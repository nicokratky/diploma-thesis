\chapter{Saving Sensor Data}
\label{ch:faps-save}

\author{Nico Kratky}
%
In order to be able to look up recent sensor readouts, all data that is received from the sensor has to be saved in a persistent way. This chapter introduces the program that was implemented to solve this task.

\section{File Type}

The Hierarchical Data Format (also called HDF) is a open source data format that allows storing large amounts of heterogenous data. Heterogenous in this context means that each entry in a dataset can itself be a complex type. This
format is often used in scientific fields because it is a very flexible format.

There are two very important terms that are used when dealing with HDF files. Groups and Datasets.

\subsection{Groups}

A group is a container that can contain other groups and/or datasets. Datasets are often stored in a group, but that does not mean that this has to be.

\subsection{Datasets}

A dataset is a the actual data that is contained. Datasets can contain multidimensional, complex and heterogenous data.

\subsection{Metadata}

It is possible to associate every file, group or dataset with metadata. This makes HDF self-describing.

\subsection{HDF and HDF5}

Although these two formats share a similar name, they are two completely different file formats.

The biggest difference is that only HDF5 uses a true hierarchical structure similar to the UNIX file system. Every object has to belong to one group. Only one group does not have a parent group, the so-called root group.
HDF uses a pseudo-flat structure using Vgroups. Objects do not necessarily have to belong to a group and there is also no root group.

\section{Structure}

In this project the structure of the HDF file are kept rather simple.

Every file represents a measuring process. Files do not have any groups. Datasets are identified by a number that represents a timestamp as microseconds since 1.1.1970 (also known as Unix Time or epoch).

\subsection{Example}

A dataset recorded on 1.1.2018 00:00:00 would have the identifier 1514764800000000. This dataset would contain a 6 dimensional integer array where each one would contain 100 values.

\section {C++ Library}

Although the HDF Group, which are the maintainers of the HDF project, offers a C++ API, it was decided against this library as it is quite complex. Instead a library developed by the Blue Brain Project, called HighFive was
used \autocite{HighFive}. This library allows for easy creation and modification of HDF5 files.

\section{Implementation}

To save the sensor data to HDF5 files a seperate command-line program was developed. This application acts as another client to FaPS, which transmitts the sensor data over the network anyways. This approach yields two
major advantages: Perfomance and hidden complexity.

Perfomance is increased as FaPS can finish one iteration of its main loop faster as it does not have to save the data and can carry on receiving data from the sensor.

\subsection{Command Line Interface}

As described in chapter \vref{ch:faps}, Boosts Program\_options were used in this project to parse command line arguments. This program has only a few parameters that are depicted in table \vref{tab:faps-save_arguments}.

\begin{table}[h]
    \centering
    \begin{tabular}{| l | l | l | p{5cm} |}
    \hline
    \textbf{Flag} & \textbf{Argument} & \textbf{Default value} & \textbf{Description} \\ \hline
    -h, -{}-help & & & Outputs the usage information \\ \hline
    -{}-version & & & Prints version information \\ \hline
    -l, -{}-loglevel & \textit{loglevel} & info & Information granularity during runtime \\ \hline
    -{}-ip & \textit{ip\_adress} & 127.0.0.1 & IP address of FaPS \\ \hline
    -{}-port & \textit{port number} & 9760 & Port of FaPS \\ \hline
    -f, -{}-filename & \textit{filename} & & Filename to which the data will be saved \\ \hline
    -i, -{}-interval & \textit{seconds} & 1 & Compression level \\ \hline
    \end{tabular}
    \caption{Flags that can be set, which arguments they take, their default values and what they do or change}
    \label{tab:faps-save_arguments}
\end{table}

\subsection{Compression}

As GRAMOC handles a lot of sensor data it is not very practical to save each sensor readout as seperate HDF5 dataset. Therefore readouts in a specified time frame are consolidated and stored in a mutual dataset. This dataset's ID is set to the timestamp of the first sensor readout that is stored in this dataset.
